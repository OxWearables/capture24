{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Notebook\n",
    "\n",
    "This notebook is a demonstration of the benchmarking for HAR models trained and validated on the Capture-24 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages and local functions\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from prepare_data import download_capture24, load_all_and_make_windows\n",
    "from benchmark import train_test_split\n",
    "from classifier import Classifier\n",
    "from eval import metrics_report, performance_table\n",
    "\n",
    "# Set import constant values\n",
    "N_JOBS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must first download the dataset, to an appropriate local folder. \n",
    "These needs to be done only once but can take some time. \n",
    "After this, the downloaded folder is extracted, and prepared into data usable for this analysis.\n",
    "Within this preparation, we:\n",
    "1. Divide it into winsec (set to 10 seconds) windows\n",
    "1. Extract annotations based on the most frequent labelled activity in the window\n",
    "1. Translate raw annotation into desired labels, using the appropriate column in the annotation dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using saved capture-24 data at \"data\\capture24\".\n",
      "Using files saved at \"prepared_data\".\n"
     ]
    }
   ],
   "source": [
    "# Download and extract Capture-24 data\n",
    "download_capture24('data')\n",
    "\n",
    "# Prepare data for HAR classifier\n",
    "load_all_and_make_windows('data', ['Walmsley2020', 'WillettsSpecific2018'], 'prepared_data', N_JOBS, winsec=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all prepared datasets, note here we use Walmsley labels\n",
    "X = np.load('prepared_data/X.npy')\n",
    "Y = np.load('prepared_data/Y_Walmsley2020.npy')\n",
    "T = np.load('prepared_data/T.npy')\n",
    "P = np.load('prepared_data/P.npy')\n",
    "X_feats = pd.read_pickle('prepared_data/X_feats.pkl').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the evalution of performance of each model, we train on the first 101 participants, and evaluate on the last 50.\n",
    "\n",
    "We can make various different classifiers with different window classifier and smoothers, based on the model type string.\n",
    "\n",
    "Note: these models are all loaded with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting of train and test based on participant id\n",
    "train_ids, test_ids = train_test_split(P)\n",
    "\n",
    "X_train, y_train, P_train = X_feats[train_ids], Y[train_ids], P[train_ids]\n",
    "X_test, y_test, P_test = X_feats[test_ids], Y[test_ids], P[test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = Classifier('rf', verbose=1)\n",
    "rf_hmm_model = Classifier('rf_hmm', verbose=1)\n",
    "xgb_model = Classifier('xgb')\n",
    "xgb_hmm_model = Classifier('xgb_hmm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=12)]: Done 2426 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=12)]: Done 3000 out of 3000 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=12)]: Done 2426 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=12)]: Done 3000 out of 3000 | elapsed:   27.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Random Forest, no smoothing =========================\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            light       0.61      0.66      0.64     64484\n",
      "moderate-vigorous       0.53      0.63      0.58     18376\n",
      "        sedentary       0.78      0.68      0.73    115213\n",
      "            sleep       0.87      0.91      0.89    110375\n",
      "\n",
      "         accuracy                           0.76    308448\n",
      "        macro avg       0.70      0.72      0.71    308448\n",
      "     weighted avg       0.76      0.76      0.76    308448\n",
      "\n",
      " Random Forest, no smoothing/bacc: 0.721 (0.719, 0.723)\n",
      "   Random Forest, no smoothing/f1: 0.706 (0.704, 0.709)\n",
      "  Random Forest, no smoothing/phi: 0.648 (0.646, 0.650)\n",
      "Random Forest, no smoothing/kappa: 0.647 (0.645, 0.649)\n"
     ]
    }
   ],
   "source": [
    "rf_model.fit(X_train, y_train, P_train)\n",
    "y_pred_rf = rf_model.predict(X_test, P_test)\n",
    "\n",
    "# Here we choose to visualise a more in depth report of this model's performance\n",
    "performance_rf = metrics_report(y_test, y_pred_rf, tag='Random Forest, no smoothing', n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=12)]: Done 2426 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=12)]: Done 3000 out of 3000 | elapsed:  5.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=12)]: Done 2426 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=12)]: Done 3000 out of 3000 | elapsed:   26.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_hmm_model.fit(X_train, y_train, P_train)\n",
    "y_pred_rf_hmm = rf_hmm_model.predict(X_test, P_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train, y_train, P_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test, P_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hmm_model.fit(X_train, y_train, P_train)\n",
    "y_pred_xgb_hmm = xgb_hmm_model.predict(X_test, P_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_dc3c4\">\n",
       "  <caption>Walmsley's labels (Sleep, Sedentary, Light and MVPA)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dc3c4_level0_col0\" class=\"col_heading level0 col0\" >Balanced Accuracy</th>\n",
       "      <th id=\"T_dc3c4_level0_col1\" class=\"col_heading level0 col1\" >Macro F1</th>\n",
       "      <th id=\"T_dc3c4_level0_col2\" class=\"col_heading level0 col2\" >Matthews Correlation Coefficient</th>\n",
       "      <th id=\"T_dc3c4_level0_col3\" class=\"col_heading level0 col3\" >Cohen's kappa score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dc3c4_level0_row0\" class=\"row_heading level0 row0\" >Random Forest</th>\n",
       "      <td id=\"T_dc3c4_row0_col0\" class=\"data row0 col0\" >0.721 (0.693, 0.744)</td>\n",
       "      <td id=\"T_dc3c4_row0_col1\" class=\"data row0 col1\" >0.706 (0.687, 0.728)</td>\n",
       "      <td id=\"T_dc3c4_row0_col2\" class=\"data row0 col2\" >0.648 (0.628, 0.668)</td>\n",
       "      <td id=\"T_dc3c4_row0_col3\" class=\"data row0 col3\" >0.647 (0.626, 0.667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc3c4_level0_row1\" class=\"row_heading level0 row1\" >XGBoost</th>\n",
       "      <td id=\"T_dc3c4_row1_col0\" class=\"data row1 col0\" >0.672 (0.645, 0.694)</td>\n",
       "      <td id=\"T_dc3c4_row1_col1\" class=\"data row1 col1\" >0.694 (0.669, 0.720)</td>\n",
       "      <td id=\"T_dc3c4_row1_col2\" class=\"data row1 col2\" >0.650 (0.627, 0.668)</td>\n",
       "      <td id=\"T_dc3c4_row1_col3\" class=\"data row1 col3\" >0.648 (0.626, 0.668)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc3c4_level0_row2\" class=\"row_heading level0 row2\" >Random Forest + HMM</th>\n",
       "      <td id=\"T_dc3c4_row2_col0\" class=\"data row2 col0\" >0.810 (0.774, 0.840)</td>\n",
       "      <td id=\"T_dc3c4_row2_col1\" class=\"data row2 col1\" >0.811 (0.782, 0.841)</td>\n",
       "      <td id=\"T_dc3c4_row2_col2\" class=\"data row2 col2\" >0.795 (0.762, 0.823)</td>\n",
       "      <td id=\"T_dc3c4_row2_col3\" class=\"data row2 col3\" >0.794 (0.761, 0.822)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc3c4_level0_row3\" class=\"row_heading level0 row3\" >XGBoost + HMM</th>\n",
       "      <td id=\"T_dc3c4_row3_col0\" class=\"data row3 col0\" >0.798 (0.761, 0.827)</td>\n",
       "      <td id=\"T_dc3c4_row3_col1\" class=\"data row3 col1\" >0.805 (0.778, 0.837)</td>\n",
       "      <td id=\"T_dc3c4_row3_col2\" class=\"data row3 col2\" >0.796 (0.765, 0.823)</td>\n",
       "      <td id=\"T_dc3c4_row3_col3\" class=\"data row3 col3\" >0.795 (0.764, 0.823)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "performance_table(y_test, {'Random Forest': y_pred_rf,\n",
    "                           'XGBoost': y_pred_xgb,\n",
    "                           'Random Forest + HMM': y_pred_rf_hmm,\n",
    "                           'XGBoost + HMM': y_pred_xgb_hmm}, P_test, \n",
    "                           \"Walmsley's labels (Sleep, Sedentary, Light and MVPA)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
